{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b35c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "XGBOOST MODEL FOR COMPLEX FEATURE INTERACTIONS IN SOLAR POWER PREDICTION\n",
      "================================================================================\n",
      "\n",
      "1. Loading processed data...\n",
      "\n",
      "2. Creating XGBoost-specific features...\n",
      "Warning: Dewpoint not found in data columns. Using zero values.\n",
      "Warning: WindSpeed not found in data columns. Using zero values.\n",
      "Warning: WindDirection not found in data columns. Using zero values.\n",
      "Warning: DNI not found in data columns. Using zero values.\n",
      "Warning: Cloud_Coverage not found in data columns. Using zero values.\n",
      "Warning: Dewpoint not found in data columns. Using zero values.\n",
      "Warning: WindSpeed not found in data columns. Using zero values.\n",
      "Warning: WindDirection not found in data columns. Using zero values.\n",
      "Warning: DNI not found in data columns. Using zero values.\n",
      "Warning: Cloud_Coverage not found in data columns. Using zero values.\n",
      "\n",
      "3. Standardizing numeric features...\n",
      "Standardizing 15 numeric features\n",
      "\n",
      "4. Training XGBoost model...\n",
      "Training with 1000 boosting rounds and early stopping of 50 rounds\n",
      "[0]\tvalidation-rmse:6.74844\n",
      "[100]\tvalidation-rmse:4.80228\n",
      "[200]\tvalidation-rmse:4.73822\n",
      "[300]\tvalidation-rmse:4.70220\n",
      "[400]\tvalidation-rmse:4.67632\n",
      "[500]\tvalidation-rmse:4.65755\n",
      "[600]\tvalidation-rmse:4.64119\n",
      "[700]\tvalidation-rmse:4.62725\n",
      "[800]\tvalidation-rmse:4.61688\n",
      "[900]\tvalidation-rmse:4.60784\n",
      "[999]\tvalidation-rmse:4.60183\n",
      "Model saved to xgboost_model/xgboost_solar_model.json\n",
      "\n",
      "5. Evaluating model performance...\n",
      "RMSE: 4.8426 MW\n",
      "MAE: 2.8623 MW\n",
      "R²: 0.5276\n",
      "\n",
      "Daytime-only metrics:\n",
      "Daytime RMSE: 5.7539 MW\n",
      "Daytime MAE: 4.0409 MW\n",
      "Daytime R²: 0.4272\n",
      "\n",
      "6. Analyzing feature importance...\n",
      "\n",
      "Top most important features:\n",
      "1. Temperature_diff: 1092.324829\n",
      "2. GHI_squared: 526.526367\n",
      "3. GHI: 347.943115\n",
      "4. GHI_diff: 201.046280\n",
      "5. Temperature: 195.355988\n",
      "6. DHI: 194.711685\n",
      "7. Pressure: 170.814667\n",
      "8. Capacity_MW: 154.401596\n",
      "9. Temperature_squared: 124.207825\n",
      "10. temp_ghi: 118.428467\n",
      "\n",
      "7. Performing SHAP analysis for feature interactions...\n",
      "Calculating SHAP values on 500 samples...\n",
      "SHAP analysis completed and saved.\n",
      "\n",
      "8. Creating prediction visualizations...\n",
      "Creating hourly plot for example day: 2006-03-07\n",
      "\n",
      "9. Creating prediction accuracy heatmap by hour and month...\n",
      "\n",
      "10. Analyzing weather feature interactions...\n",
      "Created weather interaction plots for GHI and Temperature\n",
      "\n",
      "11. Saving prediction results...\n",
      "\n",
      "XGBoost model training and evaluation completed!\n",
      "This implementation focuses on XGBoost's strengths in modeling complex weather feature interactions\n",
      "Check the 'xgboost_model' directory for all outputs:\n",
      "  - Model: xgboost_model/xgboost_solar_model.json\n",
      "  - Plots: xgboost_model/plots/\n",
      "  - Data: xgboost_model/data/\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create dedicated directory for XGBoost model outputs\n",
    "model_dir = 'xgboost_model'\n",
    "os.makedirs(f'{model_dir}/plots', exist_ok=True)\n",
    "os.makedirs(f'{model_dir}/data', exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"XGBOOST MODEL FOR COMPLEX FEATURE INTERACTIONS IN SOLAR POWER PREDICTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Load the processed data\n",
    "print(\"\\n1. Loading processed data...\")\n",
    "train_data = pd.read_csv('processed_data/train_all_predict_one/train_data.csv')\n",
    "test_data = pd.read_csv('processed_data/train_all_predict_one/test_data.csv')\n",
    "\n",
    "# Convert datetime for easier analysis\n",
    "train_data['LocalTime'] = pd.to_datetime(train_data['LocalTime'])\n",
    "test_data['LocalTime'] = pd.to_datetime(test_data['LocalTime'])\n",
    "\n",
    "# 2. Create feature sets focused on XGBoost strengths\n",
    "print(\"\\n2. Creating XGBoost-specific features...\")\n",
    "\n",
    "def create_xgboost_features(data):\n",
    "    \"\"\"Create features optimized for XGBoost focusing on weather variables and interactions\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Numeric weather features\n",
    "    weather_cols = [\n",
    "        'Temperature', 'Dewpoint', 'Pressure', 'WindSpeed', \n",
    "        'WindDirection', 'GHI', 'DNI', 'DHI', 'Cloud_Coverage'\n",
    "    ]\n",
    "    \n",
    "    # Check if columns exist and add them\n",
    "    for col in weather_cols:\n",
    "        if col in data.columns:\n",
    "            features[col] = data[col]\n",
    "        else:\n",
    "            print(f\"Warning: {col} not found in data columns. Using zero values.\")\n",
    "            features[col] = 0\n",
    "    \n",
    "    # Feature interactions\n",
    "    if 'Temperature' in data.columns and 'GHI' in data.columns:\n",
    "        features['temp_ghi'] = data['Temperature'] * data['GHI']\n",
    "    \n",
    "    if 'WindSpeed' in data.columns and 'GHI' in data.columns:\n",
    "        features['wind_ghi'] = data['WindSpeed'] * data['GHI']\n",
    "    \n",
    "    if 'Cloud_Coverage' in data.columns and 'GHI' in data.columns:\n",
    "        features['cloud_ghi'] = (100 - data['Cloud_Coverage']) * data['GHI'] / 100\n",
    "    \n",
    "    # Gradient features\n",
    "    for col in ['Temperature', 'GHI', 'Cloud_Coverage']:\n",
    "        if col in data.columns:\n",
    "            try:\n",
    "                features[f'{col}_diff'] = data.groupby('location_id')[col].diff().fillna(0)\n",
    "            except:\n",
    "                print(f\"Warning: Could not calculate gradient for {col}\")\n",
    "    \n",
    "    # Add polynomial features for key variables\n",
    "    for col in ['GHI', 'Temperature']:\n",
    "        if col in data.columns:\n",
    "            features[f'{col}_squared'] = data[col] ** 2\n",
    "    \n",
    "    # Include Capacity_MW if available\n",
    "    if 'Capacity_MW' in data.columns:\n",
    "        features['Capacity_MW'] = data['Capacity_MW']\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Create feature sets\n",
    "X_train_xgb = create_xgboost_features(train_data)\n",
    "X_test_xgb = create_xgboost_features(test_data)\n",
    "\n",
    "# For XGBoost, we should standardize numeric features for better performance\n",
    "print(\"\\n3. Standardizing numeric features...\")\n",
    "numeric_cols = X_train_xgb.columns\n",
    "\n",
    "print(f\"Standardizing {len(numeric_cols)} numeric features\")\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_xgb[numeric_cols] = scaler.fit_transform(X_train_xgb[numeric_cols])\n",
    "X_test_xgb[numeric_cols] = scaler.transform(X_test_xgb[numeric_cols])\n",
    "\n",
    "# Save scaler for future use\n",
    "with open(f'{model_dir}/data/feature_scaler.pkl', 'wb') as f:\n",
    "    import pickle\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Target variable\n",
    "y_train = train_data['Power(MW)']\n",
    "y_test = test_data['Power(MW)']\n",
    "\n",
    "# Generate night mask for test data\n",
    "test_night_mask = ~test_data['LocalTime'].dt.hour.between(5, 21)\n",
    "\n",
    "# 4. Train the XGBoost model\n",
    "print(\"\\n4. Training XGBoost model...\")\n",
    "\n",
    "# Create validation set\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_xgb, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create DMatrix objects (XGBoost's optimized data structure)\n",
    "dtrain = xgb.DMatrix(X_train_final, label=y_train_final)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test_xgb, label=y_test)\n",
    "\n",
    "# Model parameters optimized for complex feature interactions\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # Regression task\n",
    "    'max_depth': 8,                   # Deeper trees for complex interactions\n",
    "    'eta': 0.05,                      # Learning rate\n",
    "    'subsample': 0.8,                 # Prevents overfitting\n",
    "    'colsample_bytree': 0.8,          # Prevents overfitting\n",
    "    'min_child_weight': 3,            # Controls complexity\n",
    "    'gamma': 0.1,                     # Minimum loss reduction for split\n",
    "    'alpha': 0.1,                     # L1 regularization\n",
    "    'lambda': 1.0,                    # L2 regularization\n",
    "    'tree_method': 'hist',            # Faster training method\n",
    "    'seed': 42                        # Reproducibility\n",
    "}\n",
    "\n",
    "# Number of boosting rounds with early stopping\n",
    "num_boost_round = 1000\n",
    "early_stopping_rounds = 50\n",
    "\n",
    "print(f\"Training with {num_boost_round} boosting rounds and early stopping of {early_stopping_rounds} rounds\")\n",
    "\n",
    "# Train model with early stopping\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dval, 'validation')],\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model_path = f'{model_dir}/xgboost_solar_model.json'\n",
    "model.save_model(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "print(\"\\n5. Evaluating model performance...\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Apply night mask (zero production during night)\n",
    "y_pred_masked = y_pred.copy()\n",
    "y_pred_masked[test_night_mask] = 0\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_masked))\n",
    "mae = mean_absolute_error(y_test, y_pred_masked)\n",
    "r2 = r2_score(y_test, y_pred_masked)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f} MW\")\n",
    "print(f\"MAE: {mae:.4f} MW\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# Calculate daytime-only metrics\n",
    "day_mask = ~test_night_mask\n",
    "if np.any(day_mask):\n",
    "    day_rmse = np.sqrt(mean_squared_error(y_test[day_mask], y_pred_masked[day_mask]))\n",
    "    day_mae = mean_absolute_error(y_test[day_mask], y_pred_masked[day_mask])\n",
    "    day_r2 = r2_score(y_test[day_mask], y_pred_masked[day_mask])\n",
    "    print(\"\\nDaytime-only metrics:\")\n",
    "    print(f\"Daytime RMSE: {day_rmse:.4f} MW\")\n",
    "    print(f\"Daytime MAE: {day_mae:.4f} MW\")\n",
    "    print(f\"Daytime R²: {day_r2:.4f}\")\n",
    "\n",
    "# Save evaluation metrics to a file\n",
    "with open(f'{model_dir}/evaluation_metrics.txt', 'w') as f:\n",
    "    f.write(f\"XGBoost Model Evaluation Metrics\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(f\"RMSE: {rmse:.4f} MW\\n\")\n",
    "    f.write(f\"MAE: {mae:.4f} MW\\n\")\n",
    "    f.write(f\"R²: {r2:.4f}\\n\\n\")\n",
    "    \n",
    "    if np.any(day_mask):\n",
    "        f.write(\"Daytime-only metrics:\\n\")\n",
    "        f.write(f\"Daytime RMSE: {day_rmse:.4f} MW\\n\")\n",
    "        f.write(f\"Daytime MAE: {day_mae:.4f} MW\\n\")\n",
    "        f.write(f\"Daytime R²: {day_r2:.4f}\\n\")\n",
    "\n",
    "# 6. Feature importance analysis\n",
    "print(\"\\n6. Analyzing feature importance...\")\n",
    "\n",
    "# Get feature importance from the model\n",
    "importance_scores = model.get_score(importance_type='gain')\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(importance_scores.keys()),\n",
    "    'Importance': list(importance_scores.values())\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(24, 10))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.title('XGBoost Feature Importance (Gain)', fontsize=16)\n",
    "plt.xlabel('Importance Score', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_dir}/plots/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Save feature importance to CSV\n",
    "importance_df.to_csv(f'{model_dir}/data/feature_importance.csv', index=False)\n",
    "\n",
    "# Print top features\n",
    "print(\"\\nTop most important features:\")\n",
    "for i, (feature, importance) in enumerate(zip(importance_df['Feature'][:10], importance_df['Importance'][:10])):\n",
    "    print(f\"{i+1}. {feature}: {importance:.6f}\")\n",
    "\n",
    "# 7. SHAP Analysis for better feature interaction understanding\n",
    "print(\"\\n7. Performing SHAP analysis for feature interactions...\")\n",
    "\n",
    "try:\n",
    "    # Use a smaller subset for SHAP analysis to manage memory\n",
    "    shap_sample_size = min(500, X_test_xgb.shape[0])\n",
    "    X_shap = X_test_xgb.iloc[:shap_sample_size]\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    print(f\"Calculating SHAP values on {shap_sample_size} samples...\")\n",
    "    shap_values = explainer.shap_values(X_shap)\n",
    "    \n",
    "    # Plot summary\n",
    "    plt.figure(figsize=(24, 10))\n",
    "    shap.summary_plot(shap_values, X_shap, plot_type=\"bar\", show=False)\n",
    "    plt.title('Feature Impact on Solar Power Prediction (SHAP)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_dir}/plots/shap_summary.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a detailed SHAP dependency plot for top feature\n",
    "    if len(importance_df) > 0:\n",
    "        top_feature = importance_df['Feature'].iloc[0]\n",
    "        plt.figure(figsize=(24, 10))\n",
    "        shap.dependence_plot(top_feature, shap_values, X_shap, show=False)\n",
    "        plt.title(f'SHAP Dependence Plot for {top_feature}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_dir}/plots/shap_dependence_plot.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # Save SHAP values for future analysis\n",
    "    np.save(f'{model_dir}/data/shap_values.npy', shap_values)\n",
    "    \n",
    "    print(\"SHAP analysis completed and saved.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in SHAP analysis: {e}\")\n",
    "    print(\"Continuing without SHAP visualization...\")\n",
    "\n",
    "# 8. Create prediction visualizations \n",
    "print(\"\\n8. Creating prediction visualizations...\")\n",
    "\n",
    "# Prepare data for plotting\n",
    "test_results = pd.DataFrame({\n",
    "    'LocalTime': test_data['LocalTime'],\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_masked,\n",
    "    'Hour': test_data['LocalTime'].dt.hour,\n",
    "    'Date': test_data['LocalTime'].dt.date\n",
    "})\n",
    "\n",
    "# Save full results\n",
    "test_results.to_csv(f'{model_dir}/data/predictions.csv', index=False)\n",
    "\n",
    "# Calculate daily aggregated production\n",
    "daily_results = test_results.groupby('Date').agg({\n",
    "    'Actual': 'sum',\n",
    "    'Predicted': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Save daily results\n",
    "daily_results.to_csv(f'{model_dir}/data/daily_predictions.csv', index=False)\n",
    "\n",
    "# Plot daily bar chart - wide format\n",
    "plt.figure(figsize=(24, 10))\n",
    "width = 0.35\n",
    "x = np.arange(len(daily_results))\n",
    "plt.bar(x - width/2, daily_results['Actual'], width, label='Actual', alpha=0.7)\n",
    "plt.bar(x + width/2, daily_results['Predicted'], width, label='Predicted', alpha=0.7)\n",
    "\n",
    "# Format x-axis with dates\n",
    "plt.xticks(x, [d.strftime('%Y-%m-%d') for d in daily_results['Date']], rotation=45, fontsize=12)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Total Daily Power Production (MW)', fontsize=14)\n",
    "plt.title('Daily Actual vs Predicted Solar Power Production (XGBoost)', fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_dir}/plots/daily_prediction.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot hourly prediction for a sample day\n",
    "# Select a day with good sunlight\n",
    "sample_days = test_results['Date'].unique()\n",
    "if len(sample_days) > 10:\n",
    "    sample_day = sample_days[10]  # 10th test day\n",
    "else:\n",
    "    sample_day = sample_days[0]  # First available day\n",
    "print(f\"Creating hourly plot for example day: {sample_day}\")\n",
    "\n",
    "day_data = test_results[test_results['Date'] == sample_day]\n",
    "plt.figure(figsize=(24, 10))\n",
    "plt.plot(day_data['Hour'], day_data['Actual'], 'o-', label='Actual', linewidth=2, markersize=10)\n",
    "plt.plot(day_data['Hour'], day_data['Predicted'], 's-', label='Predicted', linewidth=2, markersize=10)\n",
    "plt.xlabel('Hour of Day', fontsize=14)\n",
    "plt.ylabel('Power (MW)', fontsize=14)\n",
    "plt.title(f'Hourly Solar Power Prediction for {sample_day} (XGBoost)', fontsize=16)\n",
    "plt.xticks(range(0, 24), fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_dir}/plots/hourly_prediction.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Create a heatmap of prediction accuracy by hour and month\n",
    "print(\"\\n9. Creating prediction accuracy heatmap by hour and month...\")\n",
    "\n",
    "# Add error metrics\n",
    "test_results['AbsError'] = abs(test_results['Predicted'] - test_results['Actual'])\n",
    "test_results['Month'] = test_results['LocalTime'].dt.month\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "hour_month_error = test_results.pivot_table(\n",
    "    values='AbsError', \n",
    "    index='Hour', \n",
    "    columns='Month', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(24, 12))\n",
    "sns.heatmap(hour_month_error, cmap='YlOrRd', annot=True, fmt='.2f')\n",
    "plt.title('Mean Absolute Error by Hour and Month (XGBoost)', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.ylabel('Hour of Day', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_dir}/plots/error_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Create scatter plot of predicted vs actual\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.scatter(test_results['Actual'], test_results['Predicted'], alpha=0.5)\n",
    "plt.plot([0, max(test_results['Actual'])], [0, max(test_results['Actual'])], 'r--')\n",
    "plt.xlabel('Actual Power (MW)', fontsize=14)\n",
    "plt.ylabel('Predicted Power (MW)', fontsize=14)\n",
    "plt.title('XGBoost Predicted vs Actual Solar Power', fontsize=16)\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_dir}/plots/prediction_scatter.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 10. Analyze weather feature interactions\n",
    "print(\"\\n10. Analyzing weather feature interactions...\")\n",
    "\n",
    "try:\n",
    "    # Find top two weather features\n",
    "    weather_features = [f for f in importance_df['Feature'] if f in ['GHI', 'Temperature', 'DHI', 'Pressure']]\n",
    "    if len(weather_features) >= 2:\n",
    "        feat1 = weather_features[0]\n",
    "        feat2 = weather_features[1]\n",
    "        \n",
    "        # Create a 3D visualization of the interaction\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        \n",
    "        # Get the values for these features\n",
    "        feat1_vals = X_test_xgb[feat1]\n",
    "        feat2_vals = X_test_xgb[feat2]\n",
    "        \n",
    "        # Create 3D plot\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        # Scatter plot\n",
    "        sc = ax.scatter(feat1_vals, feat2_vals, y_pred, c=y_pred, cmap='viridis', s=30, alpha=0.6)\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(feat1, fontsize=14)\n",
    "        ax.set_ylabel(feat2, fontsize=14)\n",
    "        ax.set_zlabel('Predicted Power Output (MW)', fontsize=14)\n",
    "        ax.set_title(f'XGBoost Feature Interaction: {feat1} vs {feat2}', fontsize=16)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = fig.colorbar(sc, ax=ax, pad=0.1)\n",
    "        cbar.set_label('Predicted Power (MW)', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_dir}/plots/weather_interaction_3d.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Created weather interaction plots for {feat1} and {feat2}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating weather interaction plots: {e}\")\n",
    "    print(\"Continuing without interaction plots...\")\n",
    "\n",
    "print(\"\\n11. Saving prediction results...\")\n",
    "# Already saved above, so just add a message\n",
    "\n",
    "print(\"\\nXGBoost model training and evaluation completed!\")\n",
    "print(f\"This implementation focuses on XGBoost's strengths in modeling complex weather feature interactions\")\n",
    "print(f\"Check the '{model_dir}' directory for all outputs:\")\n",
    "print(f\"  - Model: {model_dir}/xgboost_solar_model.json\")\n",
    "print(f\"  - Plots: {model_dir}/plots/\")\n",
    "print(f\"  - Data: {model_dir}/data/\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
